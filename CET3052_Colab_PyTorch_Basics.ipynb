{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabaripkumar/digipen/blob/main/CET3052_Colab_PyTorch_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y18okPMJRLyt"
      },
      "source": [
        "# Introducing PyTorch for Neural Networks\n",
        "\n",
        "Learning objectives\n",
        "\n",
        "* Computational Graphs\n",
        "* Tensors\n",
        "* Operations with tensors\n",
        "* Indexing, slicing, and joining\n",
        "* Computing gradients\n",
        "* Use CUDA tensors with GPUs (need GPU)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisite Terms\n",
        "\n",
        "\n",
        "1.   features\n",
        "2.   targets\n",
        "3.   models\n",
        "4.   parameters\n",
        "5.   hyperparameters\n",
        "6.   predictions\n",
        "7.   loss functions\n",
        "8.   learning/training\n",
        "9.   testing"
      ],
      "metadata": {
        "id": "mdBqjzqZu4kD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computational Graph\n",
        "\n",
        "* A computational graph provides a visual representation of the operations and data flow in a neural network. It enables efficient computation by breaking down deep neural network into smaller, manageable parts. This allows for optimized execution by PyTorch, which can optimize the computation by reordering operations or parallelizing them.\n",
        "\n",
        "* It promotes modularity by allowing individual parts of the model to be defined separately and then connected. Parts mean linear computation functions, activation or loss functions.\n",
        "\n",
        "* It is essentially a graph where nodes represent operations or calculations, and edges represent the tensors that flow between these parts.\n",
        "\n",
        "The below computational graph represents a basic linear function in a neural network layer: $f(A,B,C) =(A*B)+C$.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*HK6gaBlCJLQOTldCURi7qQ.gif\">\n",
        "\n",
        "The below computational graph represents a neural network layer consisting of a linear function, activation function and loss function.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*d3uM1IwDZWqvEU2G0p0gxA.gif\">"
      ],
      "metadata": {
        "id": "zRqJHr8PooRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython  import display\n",
        "from IPython.display import HTML\n",
        "\n",
        "iframe = '<iframe width=\"800\" height=\"450\" src=\"https://www.youtube.com/embed/hCP1vGoCdYU?si=O63OoSfNlDHjZENc\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>'\n",
        "\n",
        "display.display(HTML(iframe))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "g60-3CnemKLk",
        "outputId": "e0bf7318-0687-4981-99cd-d09cadf72bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"800\" height=\"450\" src=\"https://www.youtube.com/embed/hCP1vGoCdYU?si=O63OoSfNlDHjZENc\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Static vs. Dynamic Computational Graph\n",
        "Tensorflow and PyTorch are implemenation libraries that compute the above types of graphs. They use multithreads and graph theory to optimize graphs and reduce time and layers. But Tensorflow implements static computational graph and PyTorch implements Dynamic Computational Graph.\n",
        "\n",
        "### **Static Computational Graph**\n",
        "\n",
        "A static computational graph means the graph's structure is defined and compiled before it's run. Once compiled, it cannot be changed. This is what TensorFlow before v2.0, after that it embraced more dynamic graphs through Eager Execution. See a figure below as an example,\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:504/format:webp/0*4UHwQnsmUjyD7VtW.gif\">\n",
        "\n",
        "#### Advantages\n",
        "\n",
        "* Efficiency\n",
        "\n",
        "Graph is optimized in compiliation for faster execution and less resource consumption.\n",
        "\n",
        "* Portability\n",
        "\n",
        "The graph can be saved, deployed, and run without the code that generated it.\n",
        "\n",
        "* Visualization\n",
        "\n",
        "Easy to visualize and debug using tools like TensorBoard.\n",
        "\n",
        "#### Disadvantages\n",
        "\n",
        "* Less Intuitive\n",
        "\n",
        "Harder for Python programmers to debug and understand, as the code doesn't execute line by line as regular Python programs.\n",
        "\n",
        "* Flexibility\n",
        "\n",
        "Less flexible in changing the graph during runtime, making it difficult for dynamic models.\n",
        "\n",
        "### Dynamic Computational Graph\n",
        "\n",
        "A dynamic computational graph, also known as an \"imperative\" or \"define-by-run\" graph, is constructed on the fly during execution. There is no compiliation for graph. This approach is used by PyTorch.\n",
        "\n",
        "#### Advantages\n",
        "\n",
        "* Intuitiveness\n",
        "\n",
        "More intuitive and pythonic. The graph is built as the code is run, making it easier to understand and debug.\n",
        "\n",
        "* Flexibility\n",
        "\n",
        "Easy to change and adapt the graph dynamically, which is particularly useful for models where the structure changes every iteration (e.g., with variable input lengths or recursive neural networks).\n",
        "\n",
        "#### Disadvantages\n",
        "\n",
        "* Overhead\n",
        "\n",
        "The flexibility can come with a runtime overhead, as the graph needs to be built from scratch at each iteration.\n",
        "\n",
        "* Optimization\n",
        "\n",
        "Less opportunity for upfront optimization compared to static graphs."
      ],
      "metadata": {
        "id": "LVT-06PnWLwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Libraries"
      ],
      "metadata": {
        "id": "kQ_TbumOkWT9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JEKsvhVRLyv",
        "outputId": "d080b3d0-0b25-4dc9-da98-0536ff041f7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e7e3236ca50>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrO2Vts_RLyw"
      },
      "source": [
        "## Tensors\n",
        "\n",
        "Tensors are N-D arrays of numbers. N means `rank`, can be 0, 1 or any number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH5c9p-xRLyw"
      },
      "source": [
        "That is,\n",
        "\n",
        "* Rank 0 tensor is also called `Scalar Tensor`. It is a single number.\n",
        "* Rank 1 tensor is also called `Vector Tensor`. It is an array of numbers.\n",
        "* Rank 2 tensor is also called `Matrix Tensor`. It is a 2-D array of numbers.\n",
        "\n",
        "For example, a vector of dimension 64, a matrix of dimension (8,8) and 3D tensor of dimension (4,4,4) look like the below,\n",
        "\n",
        "<img src=\"https://media.licdn.com/dms/image/D5612AQEBqlkZkHGO9g/article-cover_image-shrink_600_2000/0/1707758899801?e=2147483647&v=beta&t=DoTQT8iLr0ePf-efbAMn5rd5PmiXZ3Vj_Yaewnr16j0\" width=300 height=250>\n",
        "\n",
        "**Reference**\n",
        "\n",
        "Dabhade, P. (2024). \"*Exploring Tensors in PyTorch: A Beginner's Guide*\". [Link](https://www.linkedin.com/pulse/exploring-tensors-pytorch-beginners-guide-pratik-dabhade-jpjjc/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtTf6U6JRLyw"
      },
      "source": [
        "#### Creating Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaKoNb2pRLyw"
      },
      "outputs": [],
      "source": [
        "def describe(x):\n",
        "    print(\"Type: {}\".format(x.type()))\n",
        "    print(\"Shape/size: {}\".format(x.shape))\n",
        "    print(\"Values: \\n{}\".format(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can create tensors by specifying the shape as arguments. For example, create a tensor with 2 rows, 3 columns, values from a uniform distribution on the interval $[0,1)$."
      ],
      "metadata": {
        "id": "_MzGUSt6tcb_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR0bSM51RLyw",
        "outputId": "b9f8a0b2-68da-4e43-c6ec-c7b86bec0295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1.1050e-05, 8.3391e-10, 1.7282e-04],\n",
            "        [1.4580e-19, 7.1429e+31, 1.5766e-19]])\n"
          ]
        }
      ],
      "source": [
        "describe(torch.Tensor(2, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex.** Can you create a tensor with a dimension of (3, 4, 5)?"
      ],
      "metadata": {
        "id": "lAL-HprxCn_7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "49aUgRU5C7Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a tensor from the standard normal distribution."
      ],
      "metadata": {
        "id": "czyH2fn0tlmw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4vpIjPeRLyw",
        "outputId": "65b8d8d3-fc78-4a37-d388-80429fe1368e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.0461,  0.4024, -1.0115],\n",
            "        [ 0.2167, -0.6123,  0.5036]])\n"
          ]
        }
      ],
      "source": [
        "describe(torch.randn(2, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CPi-UNURLyx"
      },
      "source": [
        "It's common in prototyping to create a tensor with some values and a specific shape. For example, initialize a tensor with dimension of (2,3) and values of **ones** or **zeros**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKHrU1V2RLyx",
        "outputId": "685b4f14-663e-46e6-c8f3-799d3dfc9ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[5., 5., 5.],\n",
            "        [5., 5., 5.]])\n"
          ]
        }
      ],
      "source": [
        "# Tensor with zeros\n",
        "describe(torch.zeros(2, 3))\n",
        "\n",
        "# Tensor with ones\n",
        "x = torch.ones(2, 3)\n",
        "describe(x)\n",
        "\n",
        "# Any function with an underscore refers to an in-place operation.\n",
        "x.fill_(5)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjRIGQUsRLyx"
      },
      "source": [
        "Note:\n",
        "\n",
        "* Tensors can be initialized and then filled in place.\n",
        "\n",
        "* Operations that end in an underscore (`_`) are in place operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH7iTY_eRLyy",
        "outputId": "46fb550b-38d0-402b-b564-42f9e8702fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 4])\n",
            "Values: \n",
            "tensor([[5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5.]])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor, then chained with functions\n",
        "x = torch.Tensor(3,4).fill_(5)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5Q9-X4DRLyy"
      },
      "source": [
        "Tensors can be initialized from a list of lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpBA-XHMRLyy",
        "outputId": "0fd35010-e9b7-4c04-a741-5af343aefdb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[1., 2.],\n",
            "        [2., 4.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor([[1, 2,],\n",
        "                  [2, 4,]])\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGVhRwCIRLyy"
      },
      "source": [
        "Tensors can be initialized from numpy matrices. It is important to convert between NumPy arrays and PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owRb0DnqRLyy",
        "outputId": "88af6d9d-3b04-4ae5-9651-56dd95b225d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.DoubleTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.8716, 0.4140, 0.1549],\n",
            "        [0.7337, 0.1130, 0.8740]], dtype=torch.float64)\n",
            "float64\n"
          ]
        }
      ],
      "source": [
        "npy = np.random.rand(2, 3)\n",
        "describe(torch.from_numpy(npy))\n",
        "print(npy.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex.** What is the difference between numpy array and tensor?\n",
        "\n",
        "**NumPy Arrays** are designed for CPU use.\n",
        "\n",
        "**Tensors** are designed to run on both CPUs and GPUs, facilitating massive parallel computing.\n",
        "\n",
        "There are other differences...\n"
      ],
      "metadata": {
        "id": "jmoYpt0bFGXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex.** Can Python's DataFrame be transformed to Tensor? Or if it's Yes, in what condition?"
      ],
      "metadata": {
        "id": "Cq3DDFslWH0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'col1': [1, 2, 3],\n",
        "    'col2': [4, 5, 6],\n",
        "    'col3': [7, 8, 9]\n",
        "})\n",
        "\n",
        "# Convert DataFrame to NumPy array\n",
        "numpy_array = df.values\n",
        "\n",
        "# Convert NumPy array to PyTorch tensor\n",
        "tensor = torch.tensor(?)\n",
        "\n",
        "# Print the tensor\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "W2mmoXJ3WUcb",
        "outputId": "e0f4d691-6afd-4362-939a-84547f2ba712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-10-5e2a0470e8bb>, line 12)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-5e2a0470e8bb>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    tensor = torch.tensor(?)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJKbo270RLyy"
      },
      "source": [
        "#### Tensor Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnZe9JkcRLyy"
      },
      "source": [
        "The FloatTensor has been the default tensor that we have been creating so far. There are other base types. For example, integer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOqMMPsyRLyy",
        "outputId": "7a68a719-8781-4375-f14e-37461969e1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6).view(2, 3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Constructors\n",
        "\n",
        "Use contructors - FloatTensor, LongTensor to create directly. Or use the default constructor with **typecasting** method, `dtype`."
      ],
      "metadata": {
        "id": "9idBF6GWv02W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7vhR-6mRLyz",
        "outputId": "a23b009e-9a18-4cd4-b8fb-029e2b6b9c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.FloatTensor([[1, 2, 3],\n",
        "                       [4, 5, 6]])\n",
        "describe(x)\n",
        "\n",
        "x = x.long()\n",
        "describe(x)\n",
        "\n",
        "x = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]], dtype=torch.int64)\n",
        "describe(x)\n",
        "\n",
        "x = x.float()\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Operations"
      ],
      "metadata": {
        "id": "tT5BuOhWHXIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Math Operations"
      ],
      "metadata": {
        "id": "2TmEx8FtgZQS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZGywBI_RLyz",
        "outputId": "bc92c9c7-2954-4821-dfe1-e8cc2c4c2ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.2310,  0.6931, -0.2669],\n",
            "        [ 2.1785,  0.1021, -0.2590]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(2, 3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scu7zeivRLyz",
        "outputId": "45018135-3a88-4b0f-a3de-24180d3ec89a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.4619,  1.3862, -0.5337],\n",
            "        [ 4.3569,  0.2043, -0.5180]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.4619,  1.3862, -0.5337],\n",
            "        [ 4.3569,  0.2043, -0.5180]])\n"
          ]
        }
      ],
      "source": [
        "# plus\n",
        "describe(x + x)\n",
        "# add func\n",
        "describe(torch.add(x, x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Concatenation and Joining"
      ],
      "metadata": {
        "id": "gLpB0EORgjid"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP-gisPgRLyz",
        "outputId": "5fde7e9e-d8a4-4fdd-bbe3-f61dea98aa94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([6])\n",
            "Values: \n",
            "tensor([0, 1, 2, 3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EE_sGHzRLyz",
        "outputId": "d54af858-32a4-4208-b9c8-caec601d148e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "# Reshape\n",
        "x = x.view(2, 3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenation\n",
        "describe(torch.cat([x, x], dim=0)) # add as new rows\n",
        "describe(torch.cat([x, x], dim=1)) # add as new columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZtpYEz5fVQq",
        "outputId": "21fc2537-79a9-43db-bc6b-f64b25aa860e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([4, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 6])\n",
            "Values: \n",
            "tensor([[0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHqoGp5bRLy0",
        "outputId": "6dfaa4ad-806f-42dd-9810-e39e5164fbbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3])\n",
            "Values: \n",
            "tensor([3, 5, 7])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([ 3, 12])\n"
          ]
        }
      ],
      "source": [
        "describe(x)\n",
        "describe(torch.sum(x, dim=0)) # sum along rows\n",
        "describe(torch.sum(x, dim=1)) # sum along columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQh8MNLzRLy0",
        "outputId": "c26253ce-a084-44d7-a37b-266b265263cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n"
          ]
        }
      ],
      "source": [
        "describe(x)\n",
        "describe(torch.transpose(x, 0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4bAWWjRRLy0",
        "outputId": "e0aacdc2-1b0d-4d4f-bc7e-d28b118241c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([1, 2])\n",
            "Values: \n",
            "tensor([[0, 1]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([])\n",
            "Values: \n",
            "1\n"
          ]
        }
      ],
      "source": [
        "describe(x)\n",
        "\n",
        "# Slice\n",
        "describe(x[:1, :2])\n",
        "# Access one cell\n",
        "describe(x[0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.index_select`:\n",
        "\n",
        "This function selects elements from a tensor along a specified dimension using an index tensor.\n",
        "Usage: torch.index_select(input, dim, index)"
      ],
      "metadata": {
        "id": "VLX3rWbsjrSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "describe(tensor)\n",
        "print(\"\\n\")\n",
        "\n",
        "indices = torch.tensor([0, 2])\n",
        "describe(indices)\n",
        "print(\"\\n\")\n",
        "\n",
        "selected = torch.index_select(tensor, 0, indices)\n",
        "describe(selected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XKZfnmBj1Z2",
        "outputId": "ef716405-4d21-4377-f6fc-f7b6750f4dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([0, 2])\n",
            "\n",
            "\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[1, 2],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw4AOxtiRLy0",
        "outputId": "909e9d74-2f5b-45ed-ee41-3f53cdea518f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "\n",
            "\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[-0.1549, -1.3706, -0.1319],\n",
            "        [ 0.8848, -0.2611,  0.6104]])\n",
            "\n",
            "\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([-0.1549, -0.2611])\n"
          ]
        }
      ],
      "source": [
        "row_indices = torch.arange(2).long()\n",
        "col_indices = torch.LongTensor([0, 1])\n",
        "\n",
        "print(row_indices)\n",
        "print(col_indices)\n",
        "print(\"\\n\")\n",
        "\n",
        "x = torch.randn([2, 3])\n",
        "describe(x)\n",
        "print(\"\\n\")\n",
        "\n",
        "describe(x[row_indices, col_indices])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMB7qOEpRLy0"
      },
      "source": [
        "Long Tensors are used for indexing operations and mirror the `int64` numpy type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO6X4Q96RLy0",
        "outputId": "d672ef68-0588-4017-e144-c542af775f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "torch.int64\n",
            "int64\n"
          ]
        }
      ],
      "source": [
        "x = torch.LongTensor([[1, 2, 3],\n",
        "                      [4, 5, 6],\n",
        "                      [7, 8, 9]])\n",
        "describe(x)\n",
        "print(x.dtype)\n",
        "print(x.numpy().dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR8c6UsXRLy1"
      },
      "source": [
        "You can convert a FloatTensor to a LongTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85jb9DSyRLy1",
        "outputId": "0d186c70-5319-48cb-8482-5cd8e614b492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.FloatTensor([[1, 2, 3],\n",
        "                       [4, 5, 6],\n",
        "                       [7, 8, 9]])\n",
        "x = x.long()\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jruGKEGQRLy1"
      },
      "source": [
        "#### Special Tensor initializations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLfQHZHQRLy1"
      },
      "source": [
        "We can create a vector of incremental numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNmuEaGeRLy2",
        "outputId": "d84cb441-f72b-4975-884f-f9be8bf2170d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([10])\n",
            "Values: \n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(0, 10)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJYRvO5zRLy2"
      },
      "source": [
        "Sometimes it's useful to have an integer-based arange for indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWooDShhRLy2",
        "outputId": "c91cc28d-4712-49bd-a735-06fcc449bc53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([10])\n",
            "Values: \n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(0, 10).long()\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPikPfdURLy2"
      },
      "source": [
        "#### Matrix Addition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWnZofmQRLy2"
      },
      "source": [
        "* Note: Reshaping allows you to move the numbers in a tensor around.  One can be sure that the order is preserved.  In PyTorch, reshaping is called `view`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lQ8Q7JHRLy2",
        "outputId": "608bc703-dbc8-47d4-df6c-1276127825a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([20])\n",
            "Values: \n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19])\n",
            "\n",
            "\n",
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "         18, 19]])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
            "tensor([[ 0,  1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14],\n",
            "        [15, 16, 17, 18, 19]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15],\n",
            "        [16, 17, 18, 19]])\n",
            "tensor([[ 0,  1],\n",
            "        [ 2,  3],\n",
            "        [ 4,  5],\n",
            "        [ 6,  7],\n",
            "        [ 8,  9],\n",
            "        [10, 11],\n",
            "        [12, 13],\n",
            "        [14, 15],\n",
            "        [16, 17],\n",
            "        [18, 19]])\n",
            "tensor([[ 0],\n",
            "        [ 1],\n",
            "        [ 2],\n",
            "        [ 3],\n",
            "        [ 4],\n",
            "        [ 5],\n",
            "        [ 6],\n",
            "        [ 7],\n",
            "        [ 8],\n",
            "        [ 9],\n",
            "        [10],\n",
            "        [11],\n",
            "        [12],\n",
            "        [13],\n",
            "        [14],\n",
            "        [15],\n",
            "        [16],\n",
            "        [17],\n",
            "        [18],\n",
            "        [19]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(0, 20)\n",
        "describe(x)\n",
        "print(\"\\n\")\n",
        "print(x.view(1, 20))\n",
        "print(x.view(2, 10))\n",
        "print(x.view(4, 5))\n",
        "print(x.view(5, 4))\n",
        "print(x.view(10, 2))\n",
        "print(x.view(20, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzEz5WmQRLy2"
      },
      "source": [
        "Computation between different dimensions.\n",
        "\n",
        "$X_{3 \\times 4} + Y_{1 \\times 4}$ and $X_{3 \\times 4} + Z_{3 \\times 1}$ are both legitimate operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUeeIrDBRLy2",
        "outputId": "7b4500e8-bb50-49cd-ae8c-36beb5961b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x=\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "\n",
            "y=\n",
            "tensor([[0, 1, 2, 3]])\n",
            "\n",
            "z=\n",
            "tensor([[0],\n",
            "        [1],\n",
            "        [2]])\n",
            "\n",
            "\n",
            "\n",
            "x + y = \n",
            "tensor([[ 0,  2,  4,  6],\n",
            "        [ 4,  6,  8, 10],\n",
            "        [ 8, 10, 12, 14]])\n",
            "\n",
            "x + z = \n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [10, 11, 12, 13]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "y = torch.arange(4).view(1, 4)\n",
        "z = torch.arange(3).view(3, 1)\n",
        "\n",
        "print(f\"x=\\n{x}\\n\")\n",
        "print(f\"y=\\n{y}\\n\")\n",
        "print(f\"z=\\n{z}\\n\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(f\"x + y = \\n{x+y}\\n\")\n",
        "print(f\"x + z = \\n{x+z}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQuGRp0dRLy2"
      },
      "source": [
        "Unsqueeze and squeeze will add and remove 1-dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7KpSMAwRLy2",
        "outputId": "50407cf1-9f13-4009-a37a-98392989a960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 4])\n",
            "Values: \n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "--\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 1, 4])\n",
            "Values: \n",
            "tensor([[[ 0,  1,  2,  3]],\n",
            "\n",
            "        [[ 4,  5,  6,  7]],\n",
            "\n",
            "        [[ 8,  9, 10, 11]]])\n",
            "--\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 4])\n",
            "Values: \n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "describe(x)\n",
        "print(\"--\")\n",
        "x = x.unsqueeze(dim=1)\n",
        "describe(x)\n",
        "print(\"--\")\n",
        "x = x.squeeze()\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyJYCo6mRLy3"
      },
      "source": [
        "The convention of `_` indicating in-place operations continues:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZXqPMVqRLy3",
        "outputId": "6756841d-8016-4379-8a33-f5da62529304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "--\n",
            "tensor([[ 0,  2,  4,  6],\n",
            "        [ 8, 10, 12, 14],\n",
            "        [16, 18, 20, 22]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).reshape(3, 4)\n",
        "print(x)\n",
        "print(\"--\")\n",
        "print(x.add_(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehUml6SbRLy3"
      },
      "source": [
        "There are many operations to reduce a dimension.  Such as sum:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIL18iMeRLy3",
        "outputId": "7901cb91-9d23-49be-fb71-ba0f94eaa2b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: \n",
            " tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "---\n",
            "Summing across columns (dim=0): \n",
            " tensor([12, 15, 18, 21])\n",
            "---\n",
            "Summing across rows (dim=1): \n",
            " tensor([ 6, 22, 38])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).reshape(3, 4)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"---\")\n",
        "print(\"Summing across columns (dim=0): \\n\", x.sum(dim=0))\n",
        "print(\"---\")\n",
        "print(\"Summing across rows (dim=1): \\n\", x.sum(dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Multiplication"
      ],
      "metadata": {
        "id": "5fFNw3KOMCZq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_fzpCe-RLy5"
      },
      "source": [
        "A three dimensional tensor would represent a batch of sequences, where each sequence item has a feature vector.  It is common to switch the batch and sequence dimensions so that we can more easily index the sequence in a sequential model.\n",
        "\n",
        "For example, a training batch consists of 3 sentences with each sentence having 2 words, and each words being represented by 5 features. That is,\n",
        "\n",
        "`batch_size = 3,\n",
        "seq_size = 2,\n",
        "feature_size = 5`\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/static/guide/images/tensor/index1.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75SvyLGxRLy5",
        "outputId": "9b97ee6e-4400-434f-8154-181bad34031e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: \n",
            " torch.Size([3, 2, 5])\n",
            "x: \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9]],\n",
            "\n",
            "        [[10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29]]])\n",
            "-----\n",
            "x.transpose(1, 0).shape: \n",
            " torch.Size([2, 3, 5])\n",
            "x.transpose(1, 0): \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [20, 21, 22, 23, 24]],\n",
            "\n",
            "        [[ 5,  6,  7,  8,  9],\n",
            "         [15, 16, 17, 18, 19],\n",
            "         [25, 26, 27, 28, 29]]])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 3\n",
        "seq_size = 2\n",
        "feature_size = 5\n",
        "\n",
        "x = torch.arange(batch_size * seq_size * feature_size).view(batch_size, seq_size, feature_size)\n",
        "\n",
        "print(\"x.shape: \\n\", x.shape)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"-----\")\n",
        "\n",
        "print(\"x.transpose(1, 0).shape: \\n\", x.transpose(1, 0).shape)\n",
        "print(\"x.transpose(1, 0): \\n\", x.transpose(1, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Permute transpose more than 2 dimensions."
      ],
      "metadata": {
        "id": "sA4HiwxRU2-W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1m2zhmxRLy5",
        "outputId": "b0cf8ede-05ae-4ae5-e0e2-fffaf34d2ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: \n",
            " torch.Size([3, 2, 5])\n",
            "x: \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9]],\n",
            "\n",
            "        [[10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29]]])\n",
            "-----\n",
            "x.permute(1, 0, 2).shape: \n",
            " torch.Size([2, 3, 5])\n",
            "x.permute(1, 0, 2): \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [20, 21, 22, 23, 24]],\n",
            "\n",
            "        [[ 5,  6,  7,  8,  9],\n",
            "         [15, 16, 17, 18, 19],\n",
            "         [25, 26, 27, 28, 29]]])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 3\n",
        "seq_size = 2\n",
        "feature_size = 5\n",
        "\n",
        "x = torch.arange(batch_size * seq_size * feature_size).view(batch_size, seq_size, feature_size)\n",
        "\n",
        "print(\"x.shape: \\n\", x.shape)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"-----\")\n",
        "\n",
        "print(\"x.permute(1, 0, 2).shape: \\n\", x.permute(1, 0, 2).shape)\n",
        "print(\"x.permute(1, 0, 2): \\n\", x.permute(1, 0, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqoxuJi0RLy5"
      },
      "source": [
        "Matrix multiplication uses function - `mm`. For matrix multiplication, the number of columns in the first matrix must be equal to the number of rows in the second matrix. The result matrix has the number of rows of the first and the number of columns of the second matrix.. For example,\n",
        "\n",
        "$ \\mathbf{X1}_{2 \\times 3} \\times  \\mathbf{X2}_{3 \\times 5}  \\mathbf{X}_{2 \\times 5}$\n",
        "\n",
        "If you forget about the dimension of a matrix, can refer to [Dimension of a Matrix  Explanation & Examples](https://www.storyofmathematics.com/dimension-of-a-matrix/). For matrix multiplication, refer to [Wikipedia - Matrix multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeKNwwjgRLy6",
        "outputId": "3fcc8162-80e9-49d3-c1d9-4b3084bd6bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0., 1., 2.],\n",
            "        [3., 4., 5.]])\n",
            "---\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 5])\n",
            "Values: \n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n",
            "---\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 5])\n",
            "Values: \n",
            "tensor([[1., 2., 1., 1., 1.],\n",
            "        [1., 2., 1., 1., 1.],\n",
            "        [1., 2., 1., 1., 1.]])\n",
            "---\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 5])\n",
            "Values: \n",
            "tensor([[ 3.,  6.,  3.,  3.,  3.],\n",
            "        [12., 24., 12., 12., 12.]])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.arange(6).view(2, 3).float()\n",
        "describe(x1)\n",
        "print(\"---\")\n",
        "\n",
        "x2 = torch.ones(3, 5).float()\n",
        "describe(x2)\n",
        "print(\"---\")\n",
        "\n",
        "x2[:, 1] += 1\n",
        "describe(x2)\n",
        "print(\"---\")\n",
        "\n",
        "describe(torch.mm(x1, x2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QlIyeyHRLy7"
      },
      "source": [
        "See the [PyTorch Math Operations Documentation](https://pytorch.org/docs/stable/torch.html#math-operations) for more!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ghMOPZrRLy7"
      },
      "source": [
        "## Computing Gradients\n",
        "\n",
        "The neural network takes training data and keeps updating parameter values for each neuron's computation in the computation graph. For example,\n",
        "\n",
        "$y^{}=w  x + b$,\n",
        "\n",
        "where $w$ is called parameter or the weight of the linear function of predicting true $y$. $b$ is a scaler to represent random noises generated in the dataset. Our goal is to decrease $Loss = ||y^{} - y||^{2}$ by updating $w$ using gradient value:\n",
        "$$ \\frac{\\partial Loss}{\\partial w}$$\n",
        "\n",
        "<img src=\"https://i.ytimg.com/vi/b4Vyma9wPHo/maxresdefault.jpg\"></img>\n",
        "\n",
        "Reference:\n",
        "https://youtu.be/b4Vyma9wPHo?si=uoyccnCmIvjzE1Ed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iframe = '<iframe width=\"800\" height=\"500\" src=\"https://www.youtube.com/embed/nJyUyKN-XBQ?si=ZSuVgL4AkZ6y27ko\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>'\n",
        "display.display(HTML(iframe))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "B6o2tRxfbQpH",
        "outputId": "aa070b7f-ea15-4bd6-9ebe-ce4e63ab623d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"800\" height=\"500\" src=\"https://www.youtube.com/embed/nJyUyKN-XBQ?si=ZSuVgL4AkZ6y27ko\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex.**  Suppose $y=x^2$, in this case, gradient is $dy=2x$. Use `backward` to calculate gradient as below,"
      ],
      "metadata": {
        "id": "NoF2rUc8j7U-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cNgjJlJRLy7",
        "outputId": "b9a91984-52bd-4f83-c24e-11e5cacb894b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx =  tensor(2.)\n",
            "dy/dw =  tensor(1.)\n",
            "dy/db =  tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "# Set up a tensor by turning on gradient calculation on it.\n",
        "x = torch.tensor(1.0, requires_grad=True)\n",
        "w = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "# Compute the predicted y = 2x+3\n",
        "y = w * x + b\n",
        "\n",
        "# Compute the gradient of y with respect to x, dy/dx = a\n",
        "y.backward()\n",
        "\n",
        "print(\"dy/dx = \", x.grad)\n",
        "print(\"dy/dw = \", w.grad)\n",
        "print(\"dy/db = \", b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO6tMYa7RLy7"
      },
      "source": [
        "**Ex.** Find the gradient of $f(x)$ at $x=1$,\n",
        "\n",
        "$$f(x)=\\left\\{\n",
        "\\begin{array}{ll}\n",
        "    sin(x) \\text{ if } x>0 \\\\\n",
        "    cos(x) \\text{ otherwise } \\\\\n",
        "\\end{array}\n",
        "\\right.$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTcvraa-RLy7"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    if (x.data > 0).all():\n",
        "        return torch.sin(x)\n",
        "    else:\n",
        "        return torch.cos(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nYNMxhkRLy8",
        "outputId": "40787251-a22c-460c-9a12-bd6993fd30d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:  tensor([1.], requires_grad=True)\n",
            "y:  tensor([0.8415], grad_fn=<SinBackward0>)\n",
            "---\n",
            "tensor([0.5403])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0], requires_grad=True)\n",
        "y = f(x)\n",
        "print('x: ', x)\n",
        "# y = sin(1)\n",
        "print('y: ', y)\n",
        "print('---')\n",
        "\n",
        "y.backward()\n",
        "# dy/dx = cos(x) = cos(1) = 0.54030230586\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6WM3OsRLy8"
      },
      "source": [
        "We could apply this to a larger vector too, but we need to make sure the output is a scalar. The example below has an error, you need to fix it before running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvHlMlAMRLy8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "def056a0-620e-4aa7-cef1-f0b315c8b2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:  tensor([1.0000, 0.5000], requires_grad=True)\n",
            "y:  tensor([0.8415, 0.4794], grad_fn=<SinBackward0>)\n",
            "---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "grad can be implicitly created only for scalar outputs",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-68711deabe41>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# this is meant to break! can you fix it??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     raise RuntimeError(\n\u001b[0m\u001b[1;32m    134\u001b[0m                         \u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0, 0.5], requires_grad=True)\n",
        "y = f(x)\n",
        "print('x: ', x)\n",
        "print('y: ', y)\n",
        "print('---')\n",
        "\n",
        "# this is meant to break! can you fix it??\n",
        "y.backward()\n",
        "\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi_CJGK_RLy8"
      },
      "source": [
        "Solution: making the output `y` a scalar."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient function for matrix\n",
        "The matrix operation `y = (x + 2).mean()` is equal to,\n",
        "\n",
        "- $y = \\frac{1}{4} \\sum_{i=1}^{n} (x_i + 2)$.\n",
        "\n",
        "- The gradient $ \\frac{\\partial y}{\\partial x_i} $ for each element $ x_i $ can be calculated as:\n",
        "  $\n",
        "  \\frac{\\partial y}{\\partial x_i} = \\frac{1}{4} \\times \\frac{\\partial (x_i + 2)}{\\partial x_i} = \\frac{1}{4} \\times 1 = 0.25\n",
        "  $"
      ],
      "metadata": {
        "id": "jXX0j1Y0ogdn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlpA1ybKRLy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6370777-efd3-45a7-f3f1-eaf348873f8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "---\n",
            "x.grad=tensor([[0.2500, 0.2500],\n",
            "        [0.2500, 0.2500]])\n",
            "---\n",
            "y.grad_fn=<MeanBackward0 object at 0x7e7d6b2877c0>\n"
          ]
        }
      ],
      "source": [
        "# x = [[1, 1],\n",
        "#      [1, 1]]\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(f\"x = {x}\")\n",
        "print(\"---\")\n",
        "\n",
        "y = (x+2).mean()\n",
        "\n",
        "y.backward()\n",
        "\n",
        "print(f\"x.grad={x.grad}\")\n",
        "print(\"---\")\n",
        "\n",
        "print(f\"y.grad_fn={y.grad_fn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlc3VZDWRLy9"
      },
      "source": [
        "## CUDA Tensors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iframe = '<iframe width=\"800\" height=\"500\" src=\"https://www.youtube.com/embed/pPStdjuYzSI?si=amQKbW4j0eiPBv6H\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>'\n",
        "display.display(HTML(iframe))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "-o_pX8ANr2bH",
        "outputId": "0081990a-efa5-4da8-ebbf-92119ac96688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"800\" height=\"500\" src=\"https://www.youtube.com/embed/pPStdjuYzSI?si=amQKbW4j0eiPBv6H\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxVB9bfRLy9"
      },
      "source": [
        "PyTorch's operations can seamlessly be used on the GPU or on the CPU.  There are a couple basic operations for interacting in this way. From here, you will need to enable CUDA either from your own Jupyter Notebook on laptop or from Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2aunVbTRLy9"
      },
      "outputs": [],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHAJ80gvRLy9"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(3,3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSVTlDYCRLy-"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WofZ1MZeRLy-"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(3, 3).to(device)\n",
        "describe(x)\n",
        "print(x.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeUeJNTARLy-"
      },
      "outputs": [],
      "source": [
        "cpu_device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSFmY-RSRLy-"
      },
      "outputs": [],
      "source": [
        "# this will break!\n",
        "y = torch.rand(3, 3)\n",
        "\n",
        "print(x.device)\n",
        "print(y.device)\n",
        "\n",
        "# This will break and fix it.\n",
        "x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJyZiY7tRLy-"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available(): # only is GPU is available\n",
        "    a = torch.rand(3,3).to(device='cuda:0') #  CUDA Tensor\n",
        "    print(a)\n",
        "\n",
        "    b = torch.rand(3,3).cuda()\n",
        "    print(b)\n",
        "\n",
        "    print(a + b)\n",
        "\n",
        "    # Error expected, need to fix it.\n",
        "    a = a.cpu()\n",
        "\n",
        "    print(a + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "-pURLg7RRLy-"
      },
      "source": [
        "### Exercises\n",
        "\n",
        "Some of these exercises might require addtional operations at [PyTorch documentation](https://pytorch.org/docs/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnwm1XuBRLy-"
      },
      "source": [
        "#### Exercise 1\n",
        "\n",
        "Create a 2D tensor `t` (3x3) and then add a dimension of size 1 inserted at the 0th axis to reshape to (1x3x3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G6vv75TRLy-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "wCBZyfI6RLzB"
      },
      "source": [
        "#### Exercise 2\n",
        "\n",
        "Remove the extra dimension you just added to the previous tensor `t` of a dimension (3x3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1673yA4RLzB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "FBYfr0NnRLzB"
      },
      "source": [
        "#### Exercise 4\n",
        "\n",
        "Create a tensor t with dimension (3x3), and values from a normal distribution (mean=0, std=1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLLLRja7RLzC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVzIGM3URLzC"
      },
      "source": [
        "#### Exercise 5\n",
        "\n",
        "Retrieve the indexes of all the non zero elements in `tensor=([1, 1, 1, 0, 1])`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn7b4a2aRLzC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5fzBlM9RLzC"
      },
      "source": [
        "#### Exercise 6\n",
        "\n",
        "Create a random tensor of size (3,1) and then horizonally stack 4 copies together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY4Fol_ORLzC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzDKzqJjRLzC"
      },
      "source": [
        "#### Exercise 7\n",
        "\n",
        "Return the batch matrix-matrix product of two 3 dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4)). You can think of the first dimension of a and b is batch_size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz-wZ6eQRLzC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "pcrfboKgRLzC"
      },
      "source": [
        "#### Exercise 8\n",
        "\n",
        "Return the batch matrix-matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4)). b can be taken as one batch of a matrix data with dimension(5x4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Pvsg4iiRLzC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}